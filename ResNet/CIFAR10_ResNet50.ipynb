{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oPSy3VPHL5Uq"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "from ResNet import Bottleneck, ResNet, ResNet50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yFFakdIfNEEZ"
   },
   "outputs": [],
   "source": [
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomCrop(32, padding=4),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "id": "V2SCe0hDNeaV",
    "outputId": "02ea31cc-a3e8-4b9e-da02-1f2821ca4e52"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "train = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(train, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "test = torchvision.datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test, batch_size=128,shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NVrCGU9jNkJb"
   },
   "outputs": [],
   "source": [
    "classes = ['plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "obf7QfWYOBFT"
   },
   "outputs": [],
   "source": [
    "net = ResNet50(10).to('cuda')\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=0.0001)\n",
    "scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, factor = 0.1, patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Sp3I3vApPK2w",
    "outputId": "60d8be96-76cf-4ca8-8451-9ef862d1ef19"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss [1, 100](epoch, minibatch):  8.839240016937255\n",
      "Loss [1, 200](epoch, minibatch):  2.8543614387512206\n",
      "Loss [1, 300](epoch, minibatch):  2.5090506088733675\n",
      "Loss [2, 100](epoch, minibatch):  2.1302514731884004\n",
      "Loss [2, 200](epoch, minibatch):  1.9953344476222992\n",
      "Loss [2, 300](epoch, minibatch):  1.9380652523040771\n",
      "Loss [3, 100](epoch, minibatch):  1.855226961374283\n",
      "Loss [3, 200](epoch, minibatch):  1.7927296078205108\n",
      "Loss [3, 300](epoch, minibatch):  1.743425933122635\n",
      "Loss [4, 100](epoch, minibatch):  1.7187504696846008\n",
      "Loss [4, 200](epoch, minibatch):  1.687288955450058\n",
      "Loss [4, 300](epoch, minibatch):  1.665401849746704\n",
      "Loss [5, 100](epoch, minibatch):  1.6413379180431367\n",
      "Loss [5, 200](epoch, minibatch):  1.6188793969154358\n",
      "Loss [5, 300](epoch, minibatch):  1.591441843509674\n",
      "Loss [6, 100](epoch, minibatch):  1.582551372051239\n",
      "Loss [6, 200](epoch, minibatch):  1.5571859669685364\n",
      "Loss [6, 300](epoch, minibatch):  1.5410805189609527\n",
      "Loss [7, 100](epoch, minibatch):  1.5283722984790802\n",
      "Loss [7, 200](epoch, minibatch):  1.4911496341228485\n",
      "Loss [7, 300](epoch, minibatch):  1.4876199412345885\n",
      "Loss [8, 100](epoch, minibatch):  1.4896726572513581\n",
      "Loss [8, 200](epoch, minibatch):  1.444840190410614\n",
      "Loss [8, 300](epoch, minibatch):  1.4478385579586028\n",
      "Loss [9, 100](epoch, minibatch):  1.4383381915092468\n",
      "Loss [9, 200](epoch, minibatch):  1.3851233530044555\n",
      "Loss [9, 300](epoch, minibatch):  1.3953999078273773\n",
      "Loss [10, 100](epoch, minibatch):  1.3797350168228149\n",
      "Loss [10, 200](epoch, minibatch):  1.3668984162807465\n",
      "Loss [10, 300](epoch, minibatch):  1.3529738533496856\n",
      "Loss [11, 100](epoch, minibatch):  1.3527108430862427\n",
      "Loss [11, 200](epoch, minibatch):  1.3190882837772369\n",
      "Loss [11, 300](epoch, minibatch):  1.289210125207901\n",
      "Loss [12, 100](epoch, minibatch):  1.3086059510707855\n",
      "Loss [12, 200](epoch, minibatch):  1.274652873277664\n",
      "Loss [12, 300](epoch, minibatch):  1.2602075088024138\n",
      "Loss [13, 100](epoch, minibatch):  1.2712362825870513\n",
      "Loss [13, 200](epoch, minibatch):  1.2355617022514342\n",
      "Loss [13, 300](epoch, minibatch):  1.2457362633943558\n",
      "Loss [14, 100](epoch, minibatch):  1.2231375360488892\n",
      "Loss [14, 200](epoch, minibatch):  1.2079989618062974\n",
      "Loss [14, 300](epoch, minibatch):  1.2034609174728395\n",
      "Loss [15, 100](epoch, minibatch):  1.1854187709093094\n",
      "Loss [15, 200](epoch, minibatch):  1.1755084204673767\n",
      "Loss [15, 300](epoch, minibatch):  1.157737416625023\n",
      "Loss [16, 100](epoch, minibatch):  1.192123634815216\n",
      "Loss [16, 200](epoch, minibatch):  1.1370069837570191\n",
      "Loss [16, 300](epoch, minibatch):  1.1442907297611236\n",
      "Loss [17, 100](epoch, minibatch):  1.107102950811386\n",
      "Loss [17, 200](epoch, minibatch):  1.1141330301761627\n",
      "Loss [17, 300](epoch, minibatch):  1.0901018267869949\n",
      "Loss [18, 100](epoch, minibatch):  1.0941310381889344\n",
      "Loss [18, 200](epoch, minibatch):  1.0507519060373307\n",
      "Loss [18, 300](epoch, minibatch):  1.071660562157631\n",
      "Loss [19, 100](epoch, minibatch):  1.0489300626516342\n",
      "Loss [19, 200](epoch, minibatch):  1.0265987980365754\n",
      "Loss [19, 300](epoch, minibatch):  1.0444538742303848\n",
      "Loss [20, 100](epoch, minibatch):  1.0053205507993699\n",
      "Loss [20, 200](epoch, minibatch):  1.0068520921468735\n",
      "Loss [20, 300](epoch, minibatch):  0.9833028954267502\n",
      "Loss [21, 100](epoch, minibatch):  0.9830259472131729\n",
      "Loss [21, 200](epoch, minibatch):  0.9682340639829635\n",
      "Loss [21, 300](epoch, minibatch):  0.9769683623313904\n",
      "Loss [22, 100](epoch, minibatch):  0.9624786764383316\n",
      "Loss [22, 200](epoch, minibatch):  0.9280662304162979\n",
      "Loss [22, 300](epoch, minibatch):  0.9312695723772049\n",
      "Loss [23, 100](epoch, minibatch):  0.9080375480651856\n",
      "Loss [23, 200](epoch, minibatch):  0.9153354549407959\n",
      "Loss [23, 300](epoch, minibatch):  0.9088288271427154\n",
      "Loss [24, 100](epoch, minibatch):  0.8874812722206116\n",
      "Loss [24, 200](epoch, minibatch):  0.8856264269351959\n",
      "Loss [24, 300](epoch, minibatch):  0.8913706356287002\n",
      "Loss [25, 100](epoch, minibatch):  0.8780943483114243\n",
      "Loss [25, 200](epoch, minibatch):  0.8746073889732361\n",
      "Loss [25, 300](epoch, minibatch):  0.8545712912082672\n",
      "Loss [26, 100](epoch, minibatch):  0.833527010679245\n",
      "Loss [26, 200](epoch, minibatch):  0.862846450805664\n",
      "Loss [26, 300](epoch, minibatch):  0.8561604201793671\n",
      "Loss [27, 100](epoch, minibatch):  0.8465841692686081\n",
      "Loss [27, 200](epoch, minibatch):  0.8506513500213623\n",
      "Loss [27, 300](epoch, minibatch):  0.8320120567083359\n",
      "Loss [28, 100](epoch, minibatch):  0.8219020199775696\n",
      "Loss [28, 200](epoch, minibatch):  0.8109362137317657\n",
      "Loss [28, 300](epoch, minibatch):  0.7991736209392548\n",
      "Loss [29, 100](epoch, minibatch):  0.7946899974346161\n",
      "Loss [29, 200](epoch, minibatch):  0.8021908444166184\n",
      "Loss [29, 300](epoch, minibatch):  0.7956095051765442\n",
      "Loss [30, 100](epoch, minibatch):  0.7780683839321136\n",
      "Loss [30, 200](epoch, minibatch):  0.7675377279520035\n",
      "Loss [30, 300](epoch, minibatch):  0.7864366567134857\n",
      "Loss [31, 100](epoch, minibatch):  0.7492583286762238\n",
      "Loss [31, 200](epoch, minibatch):  0.7654818654060364\n",
      "Loss [31, 300](epoch, minibatch):  0.7475564414262772\n",
      "Loss [32, 100](epoch, minibatch):  0.7464428848028183\n",
      "Loss [32, 200](epoch, minibatch):  0.74605344414711\n",
      "Loss [32, 300](epoch, minibatch):  0.7464539271593094\n",
      "Loss [33, 100](epoch, minibatch):  0.7113471245765686\n",
      "Loss [33, 200](epoch, minibatch):  0.7323727625608444\n",
      "Loss [33, 300](epoch, minibatch):  0.7354452228546142\n",
      "Loss [34, 100](epoch, minibatch):  0.7045288586616516\n",
      "Loss [34, 200](epoch, minibatch):  0.7239412397146225\n",
      "Loss [34, 300](epoch, minibatch):  0.702357049882412\n",
      "Loss [35, 100](epoch, minibatch):  0.6966931942105293\n",
      "Loss [35, 200](epoch, minibatch):  0.6861495634913445\n",
      "Loss [35, 300](epoch, minibatch):  0.6926117312908172\n",
      "Loss [36, 100](epoch, minibatch):  0.6820511701703071\n",
      "Loss [36, 200](epoch, minibatch):  0.6807230353355408\n",
      "Loss [36, 300](epoch, minibatch):  0.6995807924866676\n",
      "Loss [37, 100](epoch, minibatch):  0.6681192058324814\n",
      "Loss [37, 200](epoch, minibatch):  0.6784629571437836\n",
      "Loss [37, 300](epoch, minibatch):  0.6783250313997269\n",
      "Loss [38, 100](epoch, minibatch):  0.6557750165462494\n",
      "Loss [38, 200](epoch, minibatch):  0.6511869436502457\n",
      "Loss [38, 300](epoch, minibatch):  0.6703853836655617\n",
      "Loss [39, 100](epoch, minibatch):  0.6443643879890442\n",
      "Loss [39, 200](epoch, minibatch):  0.6630928012728691\n",
      "Loss [39, 300](epoch, minibatch):  0.646601778268814\n",
      "Loss [40, 100](epoch, minibatch):  0.6537199735641479\n",
      "Loss [40, 200](epoch, minibatch):  0.6422764873504638\n",
      "Loss [40, 300](epoch, minibatch):  0.6430440771579743\n",
      "Loss [41, 100](epoch, minibatch):  0.6208404710888863\n",
      "Loss [41, 200](epoch, minibatch):  0.6468847548961639\n",
      "Loss [41, 300](epoch, minibatch):  0.6267846083641052\n",
      "Loss [42, 100](epoch, minibatch):  0.6086450031399727\n",
      "Loss [42, 200](epoch, minibatch):  0.6202251797914505\n",
      "Loss [42, 300](epoch, minibatch):  0.6238853070139885\n",
      "Loss [43, 100](epoch, minibatch):  0.6185173097252846\n",
      "Loss [43, 200](epoch, minibatch):  0.6032044097781182\n",
      "Loss [43, 300](epoch, minibatch):  0.6149302759766578\n",
      "Loss [44, 100](epoch, minibatch):  0.6147406467795372\n",
      "Loss [44, 200](epoch, minibatch):  0.6051844453811646\n",
      "Loss [44, 300](epoch, minibatch):  0.6186407184600831\n",
      "Loss [45, 100](epoch, minibatch):  0.5977083477377891\n",
      "Loss [45, 200](epoch, minibatch):  0.5842293477058411\n",
      "Loss [45, 300](epoch, minibatch):  0.5979399380087852\n",
      "Loss [46, 100](epoch, minibatch):  0.5913382676243782\n",
      "Loss [46, 200](epoch, minibatch):  0.5902311527729034\n",
      "Loss [46, 300](epoch, minibatch):  0.5711671343445778\n",
      "Loss [47, 100](epoch, minibatch):  0.5773072516918183\n",
      "Loss [47, 200](epoch, minibatch):  0.5879658138751984\n",
      "Loss [47, 300](epoch, minibatch):  0.5736844995617867\n",
      "Loss [48, 100](epoch, minibatch):  0.5691047406196594\n",
      "Loss [48, 200](epoch, minibatch):  0.5797811582684517\n",
      "Loss [48, 300](epoch, minibatch):  0.5650003811717034\n",
      "Loss [49, 100](epoch, minibatch):  0.5642372065782547\n",
      "Loss [49, 200](epoch, minibatch):  0.5789714482426643\n",
      "Loss [49, 300](epoch, minibatch):  0.5606344413757324\n",
      "Loss [50, 100](epoch, minibatch):  0.5656562167406082\n",
      "Loss [50, 200](epoch, minibatch):  0.5659125879406929\n",
      "Loss [50, 300](epoch, minibatch):  0.5555062511563301\n",
      "Loss [51, 100](epoch, minibatch):  0.5589963096380234\n",
      "Loss [51, 200](epoch, minibatch):  0.5562647691369057\n",
      "Loss [51, 300](epoch, minibatch):  0.5620793667435646\n",
      "Loss [52, 100](epoch, minibatch):  0.5478817278146744\n",
      "Loss [52, 200](epoch, minibatch):  0.5548448315262795\n",
      "Loss [52, 300](epoch, minibatch):  0.551018553674221\n",
      "Loss [53, 100](epoch, minibatch):  0.5372573563456535\n",
      "Loss [53, 200](epoch, minibatch):  0.532047936618328\n",
      "Loss [53, 300](epoch, minibatch):  0.5470021218061447\n",
      "Loss [54, 100](epoch, minibatch):  0.5318462827801704\n",
      "Loss [54, 200](epoch, minibatch):  0.531562380194664\n",
      "Loss [54, 300](epoch, minibatch):  0.5409415599703788\n",
      "Loss [55, 100](epoch, minibatch):  0.5360717245936394\n",
      "Loss [55, 200](epoch, minibatch):  0.5359487247467041\n",
      "Loss [55, 300](epoch, minibatch):  0.5337685203552246\n",
      "Loss [56, 100](epoch, minibatch):  0.5278202265501022\n",
      "Loss [56, 200](epoch, minibatch):  0.5313336753845215\n",
      "Loss [56, 300](epoch, minibatch):  0.5186288148164749\n",
      "Loss [57, 100](epoch, minibatch):  0.5166278117895127\n",
      "Loss [57, 200](epoch, minibatch):  0.5004483360052109\n",
      "Loss [57, 300](epoch, minibatch):  0.5322226944565773\n",
      "Loss [58, 100](epoch, minibatch):  0.5155257326364517\n",
      "Loss [58, 200](epoch, minibatch):  0.5150638368725776\n",
      "Loss [58, 300](epoch, minibatch):  0.527855603992939\n",
      "Loss [59, 100](epoch, minibatch):  0.5135599303245545\n",
      "Loss [59, 200](epoch, minibatch):  0.5028944450616837\n",
      "Loss [59, 300](epoch, minibatch):  0.5169031661748886\n",
      "Loss [60, 100](epoch, minibatch):  0.49445574909448625\n",
      "Loss [60, 200](epoch, minibatch):  0.5134569630026817\n",
      "Loss [60, 300](epoch, minibatch):  0.5036155226826667\n",
      "Loss [61, 100](epoch, minibatch):  0.49519878506660464\n",
      "Loss [61, 200](epoch, minibatch):  0.5081535249948501\n",
      "Loss [61, 300](epoch, minibatch):  0.5032998052239418\n",
      "Loss [62, 100](epoch, minibatch):  0.497781480550766\n",
      "Loss [62, 200](epoch, minibatch):  0.4825281220674515\n",
      "Loss [62, 300](epoch, minibatch):  0.5051576554775238\n",
      "Loss [63, 100](epoch, minibatch):  0.4705116418004036\n",
      "Loss [63, 200](epoch, minibatch):  0.4794814148545265\n",
      "Loss [63, 300](epoch, minibatch):  0.5205192571878433\n",
      "Loss [64, 100](epoch, minibatch):  0.4849816679954529\n",
      "Loss [64, 200](epoch, minibatch):  0.4939527302980423\n",
      "Loss [64, 300](epoch, minibatch):  0.48096194803714754\n",
      "Loss [65, 100](epoch, minibatch):  0.47678621411323546\n",
      "Loss [65, 200](epoch, minibatch):  0.49045946389436723\n",
      "Loss [65, 300](epoch, minibatch):  0.47963920176029207\n",
      "Loss [66, 100](epoch, minibatch):  0.48344717651605607\n",
      "Loss [66, 200](epoch, minibatch):  0.4736376956105232\n",
      "Loss [66, 300](epoch, minibatch):  0.48270602971315385\n",
      "Loss [67, 100](epoch, minibatch):  0.46687799513339995\n",
      "Loss [67, 200](epoch, minibatch):  0.4763159981369972\n",
      "Loss [67, 300](epoch, minibatch):  0.4797471961379051\n",
      "Loss [68, 100](epoch, minibatch):  0.4562823221087456\n",
      "Loss [68, 200](epoch, minibatch):  0.4788463106751442\n",
      "Loss [68, 300](epoch, minibatch):  0.4773494863510132\n",
      "Loss [69, 100](epoch, minibatch):  0.47677563488483427\n",
      "Loss [69, 200](epoch, minibatch):  0.4595793172717094\n",
      "Loss [69, 300](epoch, minibatch):  0.4738587388396263\n",
      "Loss [70, 100](epoch, minibatch):  0.459033143222332\n",
      "Loss [70, 200](epoch, minibatch):  0.4538933762907982\n",
      "Loss [70, 300](epoch, minibatch):  0.454161247164011\n",
      "Loss [71, 100](epoch, minibatch):  0.45955162674188615\n",
      "Loss [71, 200](epoch, minibatch):  0.4669695857167244\n",
      "Loss [71, 300](epoch, minibatch):  0.46416772991418837\n",
      "Loss [72, 100](epoch, minibatch):  0.4398690718412399\n",
      "Loss [72, 200](epoch, minibatch):  0.4655371907353401\n",
      "Loss [72, 300](epoch, minibatch):  0.44217260509729384\n",
      "Loss [73, 100](epoch, minibatch):  0.4422738966345787\n",
      "Loss [73, 200](epoch, minibatch):  0.4478651860356331\n",
      "Loss [73, 300](epoch, minibatch):  0.4469786891341209\n",
      "Loss [74, 100](epoch, minibatch):  0.452652185857296\n",
      "Loss [74, 200](epoch, minibatch):  0.44992151618003845\n",
      "Loss [74, 300](epoch, minibatch):  0.4409087851643562\n",
      "Loss [75, 100](epoch, minibatch):  0.45018809378147123\n",
      "Loss [75, 200](epoch, minibatch):  0.4415216711163521\n",
      "Loss [75, 300](epoch, minibatch):  0.45369074791669844\n",
      "Loss [76, 100](epoch, minibatch):  0.4358271759748459\n",
      "Loss [76, 200](epoch, minibatch):  0.44987971723079684\n",
      "Loss [76, 300](epoch, minibatch):  0.46197822034358976\n",
      "Loss [77, 100](epoch, minibatch):  0.4495241305232048\n",
      "Loss [77, 200](epoch, minibatch):  0.4328723394870758\n",
      "Loss [77, 300](epoch, minibatch):  0.44710842669010165\n",
      "Loss [78, 100](epoch, minibatch):  0.430138566493988\n",
      "Loss [78, 200](epoch, minibatch):  0.45061751931905747\n",
      "Loss [78, 300](epoch, minibatch):  0.44067456185817716\n",
      "Loss [79, 100](epoch, minibatch):  0.4371441785991192\n",
      "Loss [79, 200](epoch, minibatch):  0.42857502430677413\n",
      "Loss [79, 300](epoch, minibatch):  0.4354091404378414\n",
      "Loss [80, 100](epoch, minibatch):  0.4266621361672878\n",
      "Loss [80, 200](epoch, minibatch):  0.44032411873340604\n",
      "Loss [80, 300](epoch, minibatch):  0.43038433641195295\n",
      "Loss [81, 100](epoch, minibatch):  0.4152362994849682\n",
      "Loss [81, 200](epoch, minibatch):  0.4299368330836296\n",
      "Loss [81, 300](epoch, minibatch):  0.43515898123383523\n",
      "Loss [82, 100](epoch, minibatch):  0.4057521885633469\n",
      "Loss [82, 200](epoch, minibatch):  0.4278752975165844\n",
      "Loss [82, 300](epoch, minibatch):  0.4446417504549027\n",
      "Loss [83, 100](epoch, minibatch):  0.4321592256426811\n",
      "Loss [83, 200](epoch, minibatch):  0.4217809358239174\n",
      "Loss [83, 300](epoch, minibatch):  0.41628495454788206\n",
      "Loss [84, 100](epoch, minibatch):  0.418860921561718\n",
      "Loss [84, 200](epoch, minibatch):  0.4078247061371803\n",
      "Loss [84, 300](epoch, minibatch):  0.4230827637016773\n",
      "Loss [85, 100](epoch, minibatch):  0.4184363022446632\n",
      "Loss [85, 200](epoch, minibatch):  0.42853747457265856\n",
      "Loss [85, 300](epoch, minibatch):  0.421194339543581\n",
      "Loss [86, 100](epoch, minibatch):  0.3945658066868782\n",
      "Loss [86, 200](epoch, minibatch):  0.4248090210556984\n",
      "Loss [86, 300](epoch, minibatch):  0.4014836198091507\n",
      "Loss [87, 100](epoch, minibatch):  0.3953758604824543\n",
      "Loss [87, 200](epoch, minibatch):  0.40270566433668137\n",
      "Loss [87, 300](epoch, minibatch):  0.4346407979726791\n",
      "Loss [88, 100](epoch, minibatch):  0.39131177216768265\n",
      "Loss [88, 200](epoch, minibatch):  0.41342190772294996\n",
      "Loss [88, 300](epoch, minibatch):  0.42055966943502426\n",
      "Loss [89, 100](epoch, minibatch):  0.3993154127895832\n",
      "Loss [89, 200](epoch, minibatch):  0.40027943134307864\n",
      "Loss [89, 300](epoch, minibatch):  0.4079010629653931\n",
      "Loss [90, 100](epoch, minibatch):  0.41024216786026957\n",
      "Loss [90, 200](epoch, minibatch):  0.39797315165400504\n",
      "Loss [90, 300](epoch, minibatch):  0.41257811307907105\n",
      "Loss [91, 100](epoch, minibatch):  0.39576814725995063\n",
      "Loss [91, 200](epoch, minibatch):  0.4014496797323227\n",
      "Loss [91, 300](epoch, minibatch):  0.42784968852996824\n",
      "Loss [92, 100](epoch, minibatch):  0.39781673535704615\n",
      "Loss [92, 200](epoch, minibatch):  0.3933528487384319\n",
      "Loss [92, 300](epoch, minibatch):  0.417411085665226\n",
      "Loss [93, 100](epoch, minibatch):  0.39207191064953806\n",
      "Loss [93, 200](epoch, minibatch):  0.3904254674911499\n",
      "Loss [93, 300](epoch, minibatch):  0.4065232607722282\n",
      "Loss [94, 100](epoch, minibatch):  0.38698487982153895\n",
      "Loss [94, 200](epoch, minibatch):  0.40696744948625563\n",
      "Loss [94, 300](epoch, minibatch):  0.4168149581551552\n",
      "Loss [95, 100](epoch, minibatch):  0.3864050799608231\n",
      "Loss [95, 200](epoch, minibatch):  0.38968835815787317\n",
      "Loss [95, 300](epoch, minibatch):  0.40488335996866226\n",
      "Loss [96, 100](epoch, minibatch):  0.3776258008182049\n",
      "Loss [96, 200](epoch, minibatch):  0.399998320043087\n",
      "Loss [96, 300](epoch, minibatch):  0.41234890550374986\n",
      "Loss [97, 100](epoch, minibatch):  0.3748104391992092\n",
      "Loss [97, 200](epoch, minibatch):  0.3953130042552948\n",
      "Loss [97, 300](epoch, minibatch):  0.38361811742186547\n",
      "Loss [98, 100](epoch, minibatch):  0.3799448338150978\n",
      "Loss [98, 200](epoch, minibatch):  0.40081761837005614\n",
      "Loss [98, 300](epoch, minibatch):  0.39133093401789665\n",
      "Loss [99, 100](epoch, minibatch):  0.38404966324567796\n",
      "Loss [99, 200](epoch, minibatch):  0.387141085267067\n",
      "Loss [99, 300](epoch, minibatch):  0.3873719447851181\n",
      "Loss [100, 100](epoch, minibatch):  0.3959707449376583\n",
      "Loss [100, 200](epoch, minibatch):  0.39313841179013254\n",
      "Loss [100, 300](epoch, minibatch):  0.39064713671803475\n",
      "Loss [101, 100](epoch, minibatch):  0.38259925991296767\n",
      "Loss [101, 200](epoch, minibatch):  0.37727161556482314\n",
      "Loss [101, 300](epoch, minibatch):  0.39863600984215736\n",
      "Loss [102, 100](epoch, minibatch):  0.36940001249313353\n",
      "Loss [102, 200](epoch, minibatch):  0.3683442968130112\n",
      "Loss [102, 300](epoch, minibatch):  0.3892579409480095\n",
      "Loss [103, 100](epoch, minibatch):  0.379208252876997\n",
      "Loss [103, 200](epoch, minibatch):  0.3744164763391018\n",
      "Loss [103, 300](epoch, minibatch):  0.39919144541025164\n",
      "Loss [104, 100](epoch, minibatch):  0.3775774529576302\n",
      "Loss [104, 200](epoch, minibatch):  0.3805718170106411\n",
      "Loss [104, 300](epoch, minibatch):  0.3764234222471714\n",
      "Loss [105, 100](epoch, minibatch):  0.36263732209801675\n",
      "Loss [105, 200](epoch, minibatch):  0.3814633898437023\n",
      "Loss [105, 300](epoch, minibatch):  0.38640366077423094\n",
      "Loss [106, 100](epoch, minibatch):  0.361251565515995\n",
      "Loss [106, 200](epoch, minibatch):  0.37794685557484625\n",
      "Loss [106, 300](epoch, minibatch):  0.38354177072644235\n",
      "Loss [107, 100](epoch, minibatch):  0.35719128370285036\n",
      "Loss [107, 200](epoch, minibatch):  0.3681615675985813\n",
      "Loss [107, 300](epoch, minibatch):  0.3835552254319191\n",
      "Loss [108, 100](epoch, minibatch):  0.3459990732371807\n",
      "Loss [108, 200](epoch, minibatch):  0.37363224148750307\n",
      "Loss [108, 300](epoch, minibatch):  0.3908988712728024\n",
      "Loss [109, 100](epoch, minibatch):  0.3808039338886738\n",
      "Loss [109, 200](epoch, minibatch):  0.37834601536393164\n",
      "Loss [109, 300](epoch, minibatch):  0.3620477768778801\n",
      "Loss [110, 100](epoch, minibatch):  0.35704113021492956\n",
      "Loss [110, 200](epoch, minibatch):  0.37036731615662577\n",
      "Loss [110, 300](epoch, minibatch):  0.37806847020983697\n",
      "Loss [111, 100](epoch, minibatch):  0.3648793002963066\n",
      "Loss [111, 200](epoch, minibatch):  0.3695460321009159\n",
      "Loss [111, 300](epoch, minibatch):  0.36696819990873336\n",
      "Loss [112, 100](epoch, minibatch):  0.3497805692255497\n",
      "Loss [112, 200](epoch, minibatch):  0.3715791854262352\n",
      "Loss [112, 300](epoch, minibatch):  0.3761456596851349\n",
      "Loss [113, 100](epoch, minibatch):  0.36030389592051504\n",
      "Loss [113, 200](epoch, minibatch):  0.3580723369121552\n",
      "Loss [113, 300](epoch, minibatch):  0.37366754561662674\n",
      "Loss [114, 100](epoch, minibatch):  0.355857448130846\n",
      "Loss [114, 200](epoch, minibatch):  0.3717909619212151\n",
      "Loss [114, 300](epoch, minibatch):  0.3745942084491253\n",
      "Loss [115, 100](epoch, minibatch):  0.35502728521823884\n",
      "Loss [115, 200](epoch, minibatch):  0.3801086536049843\n",
      "Loss [115, 300](epoch, minibatch):  0.3543571825325489\n",
      "Loss [116, 100](epoch, minibatch):  0.3592769005894661\n",
      "Loss [116, 200](epoch, minibatch):  0.36883870139718056\n",
      "Loss [116, 300](epoch, minibatch):  0.3670287993550301\n",
      "Loss [117, 100](epoch, minibatch):  0.35530189946293833\n",
      "Loss [117, 200](epoch, minibatch):  0.3661247684061527\n",
      "Loss [117, 300](epoch, minibatch):  0.35167143180966376\n",
      "Loss [118, 100](epoch, minibatch):  0.3455443613231182\n",
      "Loss [118, 200](epoch, minibatch):  0.3425072169303894\n",
      "Loss [118, 300](epoch, minibatch):  0.3530725271999836\n",
      "Loss [119, 100](epoch, minibatch):  0.35234869197010993\n",
      "Loss [119, 200](epoch, minibatch):  0.3528152620792389\n",
      "Loss [119, 300](epoch, minibatch):  0.3658104398846626\n",
      "Loss [120, 100](epoch, minibatch):  0.35267854034900664\n",
      "Loss [120, 200](epoch, minibatch):  0.36587018370628355\n",
      "Loss [120, 300](epoch, minibatch):  0.34983618319034576\n",
      "Loss [121, 100](epoch, minibatch):  0.3462674055993557\n",
      "Loss [121, 200](epoch, minibatch):  0.3647799214720726\n",
      "Loss [121, 300](epoch, minibatch):  0.362434226423502\n",
      "Loss [122, 100](epoch, minibatch):  0.3419904267787933\n",
      "Loss [122, 200](epoch, minibatch):  0.34956473514437675\n",
      "Loss [122, 300](epoch, minibatch):  0.36206165090203285\n",
      "Loss [123, 100](epoch, minibatch):  0.34519577994942663\n",
      "Loss [123, 200](epoch, minibatch):  0.34915505900979044\n",
      "Loss [123, 300](epoch, minibatch):  0.3660018076002598\n",
      "Loss [124, 100](epoch, minibatch):  0.3389536565542221\n",
      "Loss [124, 200](epoch, minibatch):  0.3529126699268818\n",
      "Loss [124, 300](epoch, minibatch):  0.3584320928156376\n",
      "Loss [125, 100](epoch, minibatch):  0.2745757547020912\n",
      "Loss [125, 200](epoch, minibatch):  0.22790059849619865\n",
      "Loss [125, 300](epoch, minibatch):  0.20956130720674992\n",
      "Loss [126, 100](epoch, minibatch):  0.18237497799098493\n",
      "Loss [126, 200](epoch, minibatch):  0.1933388452231884\n",
      "Loss [126, 300](epoch, minibatch):  0.18526836052536966\n",
      "Loss [127, 100](epoch, minibatch):  0.17400821894407273\n",
      "Loss [127, 200](epoch, minibatch):  0.16326623141765595\n",
      "Loss [127, 300](epoch, minibatch):  0.16480547986924649\n",
      "Loss [128, 100](epoch, minibatch):  0.1624736401066184\n",
      "Loss [128, 200](epoch, minibatch):  0.1507112606242299\n",
      "Loss [128, 300](epoch, minibatch):  0.1602012763172388\n",
      "Loss [129, 100](epoch, minibatch):  0.14371952280402184\n",
      "Loss [129, 200](epoch, minibatch):  0.14584138613194228\n",
      "Loss [129, 300](epoch, minibatch):  0.15714668460190295\n",
      "Loss [130, 100](epoch, minibatch):  0.14310971003025771\n",
      "Loss [130, 200](epoch, minibatch):  0.15047285255044698\n",
      "Loss [130, 300](epoch, minibatch):  0.14869120560586452\n",
      "Loss [131, 100](epoch, minibatch):  0.13591380145400764\n",
      "Loss [131, 200](epoch, minibatch):  0.12753482565283775\n",
      "Loss [131, 300](epoch, minibatch):  0.13426522023975848\n",
      "Loss [132, 100](epoch, minibatch):  0.1255357664451003\n",
      "Loss [132, 200](epoch, minibatch):  0.12333543673157692\n",
      "Loss [132, 300](epoch, minibatch):  0.12769552011042834\n",
      "Loss [133, 100](epoch, minibatch):  0.1199782094731927\n",
      "Loss [133, 200](epoch, minibatch):  0.11861515365540981\n",
      "Loss [133, 300](epoch, minibatch):  0.12944098114967345\n",
      "Loss [134, 100](epoch, minibatch):  0.11577606782317161\n",
      "Loss [134, 200](epoch, minibatch):  0.1202187130972743\n",
      "Loss [134, 300](epoch, minibatch):  0.1212599566206336\n",
      "Loss [135, 100](epoch, minibatch):  0.1121910022571683\n",
      "Loss [135, 200](epoch, minibatch):  0.10954646151512862\n",
      "Loss [135, 300](epoch, minibatch):  0.11485624104738236\n",
      "Loss [136, 100](epoch, minibatch):  0.1138050353527069\n",
      "Loss [136, 200](epoch, minibatch):  0.11469013143330813\n",
      "Loss [136, 300](epoch, minibatch):  0.1149770862981677\n",
      "Loss [137, 100](epoch, minibatch):  0.10496257197111845\n",
      "Loss [137, 200](epoch, minibatch):  0.11100531533360482\n",
      "Loss [137, 300](epoch, minibatch):  0.10968413643538952\n",
      "Loss [138, 100](epoch, minibatch):  0.10927507575601339\n",
      "Loss [138, 200](epoch, minibatch):  0.10147064968943596\n",
      "Loss [138, 300](epoch, minibatch):  0.09852944605052472\n",
      "Loss [139, 100](epoch, minibatch):  0.10008480526506901\n",
      "Loss [139, 200](epoch, minibatch):  0.09973813395947217\n",
      "Loss [139, 300](epoch, minibatch):  0.10994329303503036\n",
      "Loss [140, 100](epoch, minibatch):  0.09728149063885212\n",
      "Loss [140, 200](epoch, minibatch):  0.10047981210052967\n",
      "Loss [140, 300](epoch, minibatch):  0.09900152161717415\n",
      "Loss [141, 100](epoch, minibatch):  0.09882153782993555\n",
      "Loss [141, 200](epoch, minibatch):  0.09600843213498593\n",
      "Loss [141, 300](epoch, minibatch):  0.08927489314228296\n",
      "Loss [142, 100](epoch, minibatch):  0.08919163968414068\n",
      "Loss [142, 200](epoch, minibatch):  0.0945032512396574\n",
      "Loss [142, 300](epoch, minibatch):  0.0904152081720531\n",
      "Loss [143, 100](epoch, minibatch):  0.08809526942670345\n",
      "Loss [143, 200](epoch, minibatch):  0.09453827252611519\n",
      "Loss [143, 300](epoch, minibatch):  0.08901693891733885\n",
      "Loss [144, 100](epoch, minibatch):  0.08728643577545882\n",
      "Loss [144, 200](epoch, minibatch):  0.07892006158828735\n",
      "Loss [144, 300](epoch, minibatch):  0.08468541529029608\n",
      "Loss [145, 100](epoch, minibatch):  0.08363243386149406\n",
      "Loss [145, 200](epoch, minibatch):  0.08623464576900006\n",
      "Loss [145, 300](epoch, minibatch):  0.0881262375600636\n",
      "Loss [146, 100](epoch, minibatch):  0.08025822123512626\n",
      "Loss [146, 200](epoch, minibatch):  0.08137236028909683\n",
      "Loss [146, 300](epoch, minibatch):  0.08294845636934042\n",
      "Loss [147, 100](epoch, minibatch):  0.07447089921683073\n",
      "Loss [147, 200](epoch, minibatch):  0.08077028729021549\n",
      "Loss [147, 300](epoch, minibatch):  0.08693202156573535\n",
      "Loss [148, 100](epoch, minibatch):  0.07026688635349274\n",
      "Loss [148, 200](epoch, minibatch):  0.08575814723968506\n",
      "Loss [148, 300](epoch, minibatch):  0.07528316034004093\n",
      "Loss [149, 100](epoch, minibatch):  0.07796191483736038\n",
      "Loss [149, 200](epoch, minibatch):  0.07794814396649599\n",
      "Loss [149, 300](epoch, minibatch):  0.07503192286938429\n",
      "Loss [150, 100](epoch, minibatch):  0.07355786092579365\n",
      "Loss [150, 200](epoch, minibatch):  0.07198565602302551\n",
      "Loss [150, 300](epoch, minibatch):  0.07614338904619217\n",
      "Loss [151, 100](epoch, minibatch):  0.0696952274441719\n",
      "Loss [151, 200](epoch, minibatch):  0.07664596512913704\n",
      "Loss [151, 300](epoch, minibatch):  0.07621198937296868\n",
      "Loss [152, 100](epoch, minibatch):  0.07049904264509678\n",
      "Loss [152, 200](epoch, minibatch):  0.07448908409103751\n",
      "Loss [152, 300](epoch, minibatch):  0.0722444773092866\n",
      "Loss [153, 100](epoch, minibatch):  0.07408497285097837\n",
      "Loss [153, 200](epoch, minibatch):  0.07429932378232479\n",
      "Loss [153, 300](epoch, minibatch):  0.07627773340791463\n",
      "Loss [154, 100](epoch, minibatch):  0.07251217653974891\n",
      "Loss [154, 200](epoch, minibatch):  0.06886578345671296\n",
      "Loss [154, 300](epoch, minibatch):  0.07596122696995736\n",
      "Loss [155, 100](epoch, minibatch):  0.06036315029487014\n",
      "Loss [155, 200](epoch, minibatch):  0.06643758732825518\n",
      "Loss [155, 300](epoch, minibatch):  0.0678966423124075\n",
      "Loss [156, 100](epoch, minibatch):  0.06482726924121379\n",
      "Loss [156, 200](epoch, minibatch):  0.06206686893478036\n",
      "Loss [156, 300](epoch, minibatch):  0.06706166461110115\n",
      "Loss [157, 100](epoch, minibatch):  0.061307161506265404\n",
      "Loss [157, 200](epoch, minibatch):  0.05830227831378579\n",
      "Loss [157, 300](epoch, minibatch):  0.06689968667924404\n",
      "Loss [158, 100](epoch, minibatch):  0.058500857651233674\n",
      "Loss [158, 200](epoch, minibatch):  0.0662197027541697\n",
      "Loss [158, 300](epoch, minibatch):  0.06511821905151009\n",
      "Loss [159, 100](epoch, minibatch):  0.056493834406137464\n",
      "Loss [159, 200](epoch, minibatch):  0.05936595628038049\n",
      "Loss [159, 300](epoch, minibatch):  0.06405909527093172\n",
      "Loss [160, 100](epoch, minibatch):  0.0620882386341691\n",
      "Loss [160, 200](epoch, minibatch):  0.0671468859165907\n",
      "Loss [160, 300](epoch, minibatch):  0.06453811233863234\n",
      "Loss [161, 100](epoch, minibatch):  0.05737098846584558\n",
      "Loss [161, 200](epoch, minibatch):  0.05518507042899728\n",
      "Loss [161, 300](epoch, minibatch):  0.059649915415793654\n",
      "Loss [162, 100](epoch, minibatch):  0.055831551291048526\n",
      "Loss [162, 200](epoch, minibatch):  0.05499050464481115\n",
      "Loss [162, 300](epoch, minibatch):  0.0628994096070528\n",
      "Loss [163, 100](epoch, minibatch):  0.05985814977437258\n",
      "Loss [163, 200](epoch, minibatch):  0.060354581326246264\n",
      "Loss [163, 300](epoch, minibatch):  0.0627272029966116\n",
      "Loss [164, 100](epoch, minibatch):  0.05714571725577116\n",
      "Loss [164, 200](epoch, minibatch):  0.054981582798063755\n",
      "Loss [164, 300](epoch, minibatch):  0.05704518230631948\n",
      "Loss [165, 100](epoch, minibatch):  0.05408035064116121\n",
      "Loss [165, 200](epoch, minibatch):  0.05964760657399893\n",
      "Loss [165, 300](epoch, minibatch):  0.053540941476821896\n",
      "Loss [166, 100](epoch, minibatch):  0.056790421810001136\n",
      "Loss [166, 200](epoch, minibatch):  0.050547503493726255\n",
      "Loss [166, 300](epoch, minibatch):  0.05958049297332764\n",
      "Loss [167, 100](epoch, minibatch):  0.05472408337518573\n",
      "Loss [167, 200](epoch, minibatch):  0.05718009475618601\n",
      "Loss [167, 300](epoch, minibatch):  0.05491965893656015\n",
      "Loss [168, 100](epoch, minibatch):  0.051263665817677974\n",
      "Loss [168, 200](epoch, minibatch):  0.05783386977389455\n",
      "Loss [168, 300](epoch, minibatch):  0.04919152554124594\n",
      "Loss [169, 100](epoch, minibatch):  0.052700967714190486\n",
      "Loss [169, 200](epoch, minibatch):  0.05077950274571776\n",
      "Loss [169, 300](epoch, minibatch):  0.05193569347262383\n",
      "Loss [170, 100](epoch, minibatch):  0.05093814089894295\n",
      "Loss [170, 200](epoch, minibatch):  0.05232907233759761\n",
      "Loss [170, 300](epoch, minibatch):  0.058492430597543714\n",
      "Loss [171, 100](epoch, minibatch):  0.04809644397348165\n",
      "Loss [171, 200](epoch, minibatch):  0.04822698749601841\n",
      "Loss [171, 300](epoch, minibatch):  0.04737004151567817\n",
      "Loss [172, 100](epoch, minibatch):  0.04959821948781609\n",
      "Loss [172, 200](epoch, minibatch):  0.048613924365490675\n",
      "Loss [172, 300](epoch, minibatch):  0.04811608199030161\n",
      "Loss [173, 100](epoch, minibatch):  0.05222764510661364\n",
      "Loss [173, 200](epoch, minibatch):  0.05422562401741743\n",
      "Loss [173, 300](epoch, minibatch):  0.05661549609154463\n",
      "Loss [174, 100](epoch, minibatch):  0.05212319299578667\n",
      "Loss [174, 200](epoch, minibatch):  0.04867717148736119\n",
      "Loss [174, 300](epoch, minibatch):  0.051791660711169245\n",
      "Loss [175, 100](epoch, minibatch):  0.04901155410334468\n",
      "Loss [175, 200](epoch, minibatch):  0.05254359154030681\n",
      "Loss [175, 300](epoch, minibatch):  0.051361130569130185\n",
      "Loss [176, 100](epoch, minibatch):  0.056696265991777184\n",
      "Loss [176, 200](epoch, minibatch):  0.057765098493546246\n",
      "Loss [176, 300](epoch, minibatch):  0.05033251633867621\n",
      "Loss [177, 100](epoch, minibatch):  0.047747475747019055\n",
      "Loss [177, 200](epoch, minibatch):  0.05219324320554733\n",
      "Loss [177, 300](epoch, minibatch):  0.0493961656652391\n",
      "Loss [178, 100](epoch, minibatch):  0.04632460195571184\n",
      "Loss [178, 200](epoch, minibatch):  0.04858155118301511\n",
      "Loss [178, 300](epoch, minibatch):  0.053830772526562216\n",
      "Loss [179, 100](epoch, minibatch):  0.04543822238221765\n",
      "Loss [179, 200](epoch, minibatch):  0.047149957194924354\n",
      "Loss [179, 300](epoch, minibatch):  0.050803377628326415\n",
      "Loss [180, 100](epoch, minibatch):  0.049232794865965844\n",
      "Loss [180, 200](epoch, minibatch):  0.04929339682683349\n",
      "Loss [180, 300](epoch, minibatch):  0.04897596085444093\n",
      "Loss [181, 100](epoch, minibatch):  0.046268546655774116\n",
      "Loss [181, 200](epoch, minibatch):  0.042781891915947196\n",
      "Loss [181, 300](epoch, minibatch):  0.05060765234753489\n",
      "Loss [182, 100](epoch, minibatch):  0.04476797264069319\n",
      "Loss [182, 200](epoch, minibatch):  0.05307487161830068\n",
      "Loss [182, 300](epoch, minibatch):  0.04850761391222477\n",
      "Loss [183, 100](epoch, minibatch):  0.043931541200727224\n",
      "Loss [183, 200](epoch, minibatch):  0.04511226551607251\n",
      "Loss [183, 300](epoch, minibatch):  0.04752522405236959\n",
      "Loss [184, 100](epoch, minibatch):  0.04832927925512195\n",
      "Loss [184, 200](epoch, minibatch):  0.05141777416691184\n",
      "Loss [184, 300](epoch, minibatch):  0.04611195098608732\n",
      "Loss [185, 100](epoch, minibatch):  0.04489896455779672\n",
      "Loss [185, 200](epoch, minibatch):  0.05029143312945962\n",
      "Loss [185, 300](epoch, minibatch):  0.04505758104845881\n",
      "Loss [186, 100](epoch, minibatch):  0.043485564403235914\n",
      "Loss [186, 200](epoch, minibatch):  0.04173792021349072\n",
      "Loss [186, 300](epoch, minibatch):  0.05178328309208155\n",
      "Loss [187, 100](epoch, minibatch):  0.04555150557309389\n",
      "Loss [187, 200](epoch, minibatch):  0.045824325457215306\n",
      "Loss [187, 300](epoch, minibatch):  0.04687584307044745\n",
      "Loss [188, 100](epoch, minibatch):  0.04189886808395386\n",
      "Loss [188, 200](epoch, minibatch):  0.044915573969483376\n",
      "Loss [188, 300](epoch, minibatch):  0.046888482999056576\n",
      "Loss [189, 100](epoch, minibatch):  0.042703730929642914\n",
      "Loss [189, 200](epoch, minibatch):  0.04844313383102417\n",
      "Loss [189, 300](epoch, minibatch):  0.04827386787161231\n",
      "Loss [190, 100](epoch, minibatch):  0.03814472258090973\n",
      "Loss [190, 200](epoch, minibatch):  0.04559313138946891\n",
      "Loss [190, 300](epoch, minibatch):  0.04017418723553419\n",
      "Loss [191, 100](epoch, minibatch):  0.04222352247685194\n",
      "Loss [191, 200](epoch, minibatch):  0.0527523024007678\n",
      "Loss [191, 300](epoch, minibatch):  0.04720606388524175\n",
      "Loss [192, 100](epoch, minibatch):  0.04322879239916801\n",
      "Loss [192, 200](epoch, minibatch):  0.04275385139510036\n",
      "Loss [192, 300](epoch, minibatch):  0.0427305543795228\n",
      "Loss [193, 100](epoch, minibatch):  0.043951349519193175\n",
      "Loss [193, 200](epoch, minibatch):  0.037608045563101766\n",
      "Loss [193, 300](epoch, minibatch):  0.04689977327361703\n",
      "Loss [194, 100](epoch, minibatch):  0.04425131002441049\n",
      "Loss [194, 200](epoch, minibatch):  0.043790823165327314\n",
      "Loss [194, 300](epoch, minibatch):  0.04787272963672876\n",
      "Loss [195, 100](epoch, minibatch):  0.045910639762878416\n",
      "Loss [195, 200](epoch, minibatch):  0.04503726653754711\n",
      "Loss [195, 300](epoch, minibatch):  0.044547636974602935\n",
      "Loss [196, 100](epoch, minibatch):  0.038648189175873995\n",
      "Loss [196, 200](epoch, minibatch):  0.04546283291652799\n",
      "Loss [196, 300](epoch, minibatch):  0.046378096230328084\n",
      "Loss [197, 100](epoch, minibatch):  0.03882626427337527\n",
      "Loss [197, 200](epoch, minibatch):  0.03689012542366982\n",
      "Loss [197, 300](epoch, minibatch):  0.030634157378226518\n",
      "Loss [198, 100](epoch, minibatch):  0.030805828757584097\n",
      "Loss [198, 200](epoch, minibatch):  0.029564176592975853\n",
      "Loss [198, 300](epoch, minibatch):  0.027018439136445523\n",
      "Loss [199, 100](epoch, minibatch):  0.023948805034160615\n",
      "Loss [199, 200](epoch, minibatch):  0.030192875675857066\n",
      "Loss [199, 300](epoch, minibatch):  0.025430371947586537\n",
      "Loss [200, 100](epoch, minibatch):  0.023097231648862362\n",
      "Loss [200, 200](epoch, minibatch):  0.022299093399196862\n",
      "Loss [200, 300](epoch, minibatch):  0.023658006470650434\n",
      "Training Done\n"
     ]
    }
   ],
   "source": [
    "EPOCHS = 200\n",
    "for epoch in range(EPOCHS):\n",
    "    losses = []\n",
    "    running_loss = 0\n",
    "    for i, inp in enumerate(trainloader):\n",
    "        inputs, labels = inp\n",
    "        inputs, labels = inputs.to('cuda'), labels.to('cuda')\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        losses.append(loss.item())\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        if i%100 == 0 and i > 0:\n",
    "            print(f'Loss [{epoch+1}, {i}](epoch, minibatch): ', running_loss / 100)\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_loss = sum(losses)/len(losses)\n",
    "    scheduler.step(avg_loss)\n",
    "            \n",
    "print('Training Done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "eY3rPw7wPVEe",
    "outputId": "213b5a1c-d9f4-4659-f6dc-b6ff9d0d1a44"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on 10,000 test images:  85.66 %\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testloader:\n",
    "        images, labels = data\n",
    "        images, labels = images.to('cuda'), labels.to('cuda')\n",
    "        outputs = net(images)\n",
    "        \n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print('Accuracy on 10,000 test images: ', 100*(correct/total), '%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "oeVRGN56hkNZ"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "CIFAR10-ResNet50_85%.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
